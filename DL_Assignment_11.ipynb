{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d04f735",
   "metadata": {},
   "source": [
    "# Assignment 11 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7f299",
   "metadata": {},
   "source": [
    "1. Write the Python code to implement a single neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b12b0",
   "metadata": {},
   "source": [
    "Certainly! Here's an example of Python code to implement a single neuron:\n",
    "\n",
    "```pythoN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee66b76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 0.846625859073371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        self.weights = np.random.rand(num_inputs)\n",
    "        self.bias = np.random.rand()\n",
    "    \n",
    "    def activate(self, inputs):\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        output = self.sigmoid(weighted_sum)\n",
    "        return output\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Example usage:\n",
    "neuron = Neuron(2)  # Create a neuron with 2 inputs\n",
    "inputs = np.array([0.5, 0.7])  # Input values\n",
    "output = neuron.activate(inputs)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a9346",
   "metadata": {},
   "source": [
    "In this code, we define a `Neuron` class that represents a single neuron. The constructor `__init__` initializes the neuron with random weights and a bias term. The `activate` method takes an array of input values, computes the weighted sum of inputs, adds the bias, and applies the sigmoid activation function to obtain the output of the neuron.\n",
    "\n",
    "In the example usage, we create an instance of the `Neuron` class with 2 inputs. We then provide input values in the form of a NumPy array and call the `activate` method to compute the output of the neuron. Finally, we print the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f82c49",
   "metadata": {},
   "source": [
    "2. Write the Python code to implement ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28647933",
   "metadata": {},
   "source": [
    "Certainly! Here's an example of Python code to implement the Rectified Linear Unit (ReLU) activation function:\n",
    "\n",
    "```pythoN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5107c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [0 0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Example usage:\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "output = relu(x)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1356fa",
   "metadata": {},
   "source": [
    "In this code, we define a function called `relu` that takes an input `x` and applies the ReLU activation function element-wise using NumPy's `maximum` function. The ReLU function returns the maximum value between 0 and `x`, effectively setting negative values to zero.\n",
    "\n",
    "In the example usage, we create an input array `x` with a range of values. We then pass `x` to the `relu` function to compute the output. Finally, we print the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17395475",
   "metadata": {},
   "source": [
    "3. Write the Python code for a dense layer in terms of matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b675b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ 3.10862775 -1.60617565]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(output_size)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = np.dot(inputs, self.weights) + self.bias\n",
    "        return output\n",
    "\n",
    "# Example usage:\n",
    "dense_layer = DenseLayer(3, 2)  # Create a dense layer with 3 inputs and 2 outputs\n",
    "inputs = np.array([1, 2, 3])  # Input values\n",
    "output = dense_layer.forward(inputs)\n",
    "print(\"Output:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b79123",
   "metadata": {},
   "source": [
    "In the example usage, we create an instance of the DenseLayer class with 3 inputs and 2 outputs. We then provide input values in the form of a NumPy array and call the forward method to compute the output of the layer. Finally, we print the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db87b31",
   "metadata": {},
   "source": [
    "4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions\n",
    "and functionality built into Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = [[random.random() for _ in range(output_size)] for _ in range(input_size)]\n",
    "        self.bias = [random.random() for _ in range(output_size)]\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = [sum([inputs[j] * self.weights[i][j] for j in range(len(inputs))]) + self.bias[i] for i in range(len(self.bias))]\n",
    "        return output\n",
    "\n",
    "# Example usage:\n",
    "dense_layer = DenseLayer(3, 2)  # Create a dense layer with 3 inputs and 2 outputs\n",
    "inputs = [1, 2, 3]  # Input values\n",
    "output = dense_layer.forward(inputs)\n",
    "print(\"Output:\", output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4f6c6",
   "metadata": {},
   "source": [
    "In this code, we define a DenseLayer class that represents a dense layer in a neural network. The constructor __init__ initializes the layer with random weights and biases using list comprehensions. The forward method takes a list of input values, performs the matrix multiplication-like operation using list comprehensions and built-in sum function, adds the bias term, and returns the output of the layer.\n",
    "\n",
    "In the example usage, we create an instance of the DenseLayer class with 3 inputs and 2 outputs. We then provide input values in the form of a list and call the forward method to compute the output of the layer. Finally, we print the output. Note that the weights and biases are generated using the random.random() function to generate random values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a6dff",
   "metadata": {},
   "source": [
    "5. What is the “hidden size” of a layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0fdb1",
   "metadata": {},
   "source": [
    "The \"hidden size\" of a layer refers to the number of neurons or units present in that layer. In a neural network, a layer can be composed of multiple neurons, and the hidden size represents the number of neurons in that layer excluding the input and output neurons.\n",
    "\n",
    "The hidden size determines the capacity and complexity of the layer's representation. Each neuron in the hidden layer processes and transforms the input data using its weights and activation function. The hidden size controls the number of learnable parameters in the layer, influencing the layer's ability to capture and represent complex patterns or relationships in the data.\n",
    "\n",
    "For example, in a fully connected layer of a neural network, the hidden size refers to the number of neurons in that layer, each of which receives input from all the neurons in the previous layer and provides output to all the neurons in the next layer. The hidden size is a hyperparameter of the neural network, and its choice can impact the model's performance, capacity, and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889ae4a",
   "metadata": {},
   "source": [
    "6. What does the t method do in PyTorch?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b66f1b33",
   "metadata": {},
   "source": [
    "In PyTorch, the `t` method is used to perform the transpose operation on a tensor. It returns a new tensor that has the dimensions of the original tensor transposed.\n",
    "\n",
    "Here's an example to illustrate the usage of the `t` method:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "x_transposed = x.t()\n",
    "\n",
    "print(\"Original tensor:\")\n",
    "print(x)\n",
    "\n",
    "print(\"\\nTransposed tensor:\")\n",
    "print(x_transposed)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Original tensor:\n",
    "tensor([[1, 2, 3],\n",
    "        [4, 5, 6]])\n",
    "\n",
    "Transposed tensor:\n",
    "tensor([[1, 4],\n",
    "        [2, 5],\n",
    "        [3, 6]])\n",
    "```\n",
    "\n",
    "In the example above, we have a 2-dimensional tensor `x`. By calling the `t` method on `x`, we obtain a new tensor `x_transposed` that is the transposed version of `x`. The rows of `x` become the columns of `x_transposed`, and the columns of `x` become the rows of `x_transposed`.\n",
    "\n",
    "The `t` method can be particularly useful when performing operations that require the transpose of a tensor, such as matrix multiplication, computing the dot product, or reshaping data. It provides a convenient way to manipulate the dimensions of tensors in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe8a3f",
   "metadata": {},
   "source": [
    "7. Why is matrix multiplication written in plain Python very slow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476d5ba",
   "metadata": {},
   "source": [
    "Matrix multiplication implemented in plain Python can be slower compared to optimized implementations in libraries like NumPy or libraries that utilize lower-level languages like C or CUDA. There are several reasons for this performance difference:\n",
    "\n",
    "1. Lack of vectorization: In plain Python, matrix multiplication is typically implemented using nested loops. This approach processes each element of the resulting matrix individually, which can be inefficient. On the other hand, optimized libraries like NumPy use vectorized operations, which allow for parallelized computations and take advantage of underlying hardware acceleration.\n",
    "\n",
    "2. Dynamic typing: Python is a dynamically typed language, which means that the type of variables can change at runtime. This dynamic typing introduces additional overhead compared to statically typed languages like C or Fortran, which can have a negative impact on performance, especially for large-scale matrix multiplication.\n",
    "\n",
    "3. Interpretation overhead: Python code is interpreted rather than directly compiled to machine code. The interpreter needs to translate the Python code line by line, which introduces additional overhead compared to compiled languages. In contrast, compiled languages can perform extensive optimizations during the compilation process, resulting in faster execution.\n",
    "\n",
    "4. Python's Global Interpreter Lock (GIL): The GIL is a mechanism in CPython (the reference implementation of Python) that allows only one thread to execute Python bytecode at a time. This can limit the performance of multi-threaded matrix multiplication, as the GIL prevents true parallel execution on multi-core systems.\n",
    "\n",
    "To achieve faster matrix multiplication in Python, it is recommended to leverage optimized libraries like NumPy, which internally use highly optimized routines written in low-level languages. These libraries take advantage of efficient algorithms, hardware-specific optimizations, and parallelization to perform matrix operations efficiently, resulting in significant speed improvements compared to plain Python implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ac5b6",
   "metadata": {},
   "source": [
    "8. In matmul, why is ac==br?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f3493",
   "metadata": {},
   "source": [
    "In matrix multiplication, the condition `ac == br` (where `a` is an `m x n` matrix and `b` is an `n x p` matrix) ensures that the number of columns in the left matrix (`a`) matches the number of rows in the right matrix (`b`). This condition is necessary for the matrices to be compatible for multiplication.\n",
    "\n",
    "When multiplying two matrices, the number of columns in the left matrix must be equal to the number of rows in the right matrix in order for the multiplication operation to be defined. The resulting matrix will have dimensions `m x p`, where `m` is the number of rows in the left matrix and `p` is the number of columns in the right matrix.\n",
    "\n",
    "If the condition `ac == br` is not satisfied, the matrix multiplication operation cannot be performed, as the dimensions of the matrices are incompatible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc65e904",
   "metadata": {},
   "source": [
    "9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e619d44d",
   "metadata": {},
   "source": [
    "In Jupyter Notebook, you can measure the time taken for a single cell to execute using the `%timeit` magic command or the `%%timeit` cell magic command.\n",
    "\n",
    "1. `%timeit` magic command:\n",
    "   - To measure the execution time of a single line of code, simply prefix the line with `%timeit`.\n",
    "   - For example, if you want to measure the time taken for a function call:\n",
    "     ```python\n",
    "     %timeit my_function()\n",
    "     ```\n",
    "   - The `%timeit` command will execute the line multiple times and provide the average execution time.\n",
    "\n",
    "2. `%%timeit` cell magic command:\n",
    "   - To measure the execution time of an entire cell, start the cell with `%%timeit` at the beginning.\n",
    "   - For example:\n",
    "     ```python\n",
    "     %%timeit\n",
    "     # Your code here\n",
    "     ```\n",
    "   - The `%%timeit` command will execute the entire cell multiple times and provide the average execution time.\n",
    "\n",
    "Both `%timeit` and `%%timeit` automatically determine the number of iterations needed to obtain accurate timing results. They provide information about the execution time, number of loops performed, and the best timing result obtained.\n",
    "\n",
    "Additionally, if you want more fine-grained control over timing, you can use the `time` module in Python to manually measure the execution time of specific sections of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d6502",
   "metadata": {},
   "source": [
    "10. What is elementwise arithmetic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035ecb1",
   "metadata": {},
   "source": [
    "Elementwise arithmetic refers to performing arithmetic operations on corresponding elements of two or more arrays or tensors, resulting in a new array or tensor with the same shape as the original arrays.\n",
    "\n",
    "In elementwise arithmetic, each element of the output array is computed by applying the arithmetic operation to the corresponding elements from the input arrays. The operation is performed independently on each pair of corresponding elements without any dependencies on neighboring elements.\n",
    "\n",
    "Elementwise arithmetic operations can include addition, subtraction, multiplication, division, exponentiation, and more. These operations can be performed on arrays or tensors of the same shape, or arrays and tensors that can be broadcasted to have compatible shapes.\n",
    "\n",
    "For example, given two arrays `A = [1, 2, 3]` and `B = [4, 5, 6]`, elementwise addition would result in `C = [5, 7, 9]`, where each element of `C` is the sum of the corresponding elements from `A` and `B`.\n",
    "\n",
    "Elementwise arithmetic is a fundamental operation in many numerical computing libraries and frameworks, such as NumPy, PyTorch, and TensorFlow. It allows for efficient and convenient computation of operations on arrays and tensors, enabling vectorized and parallelized calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2617cd",
   "metadata": {},
   "source": [
    "11. Write the PyTorch code to test whether every element of a is greater than the\n",
    "corresponding element of b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fab836",
   "metadata": {},
   "source": [
    "Certainly! Here's an example of PyTorch code to test whether every element of `a` is greater than the corresponding element of `b`:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "def compare_elements(a, b):\n",
    "    return torch.all(a > b)\n",
    "\n",
    "# Example usage:\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([0, 1, 2])\n",
    "\n",
    "result = compare_elements(a, b)\n",
    "print(\"All elements of 'a' are greater than corresponding elements of 'b':\", result)\n",
    "```\n",
    "\n",
    "In this code, we define a function called `compare_elements` that takes two PyTorch tensors `a` and `b`. The function uses the `>` operator to compare each element of `a` with the corresponding element of `b`. The `torch.all` function is then used to check if all the elements satisfy the condition `a > b`. It returns a boolean value indicating whether all the elements of `a` are greater than the corresponding elements of `b`.\n",
    "\n",
    "In the example usage, we create two tensors `a` and `b` with corresponding elements. We then call the `compare_elements` function with `a` and `b` as arguments and store the result in the `result` variable. Finally, we print the result indicating whether all elements of `a` are greater than the corresponding elements of `b`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c5f6c",
   "metadata": {},
   "source": [
    "12. What is a rank-0 tensor? How do you convert it to a plain Python data type?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44b088ed",
   "metadata": {},
   "source": [
    "A rank-0 tensor, also known as a scalar, is a tensor with zero dimensions. It represents a single value or element in a tensor. In PyTorch, rank-0 tensors are typically created using the `torch.tensor()` function or by indexing into other tensors.\n",
    "\n",
    "To convert a rank-0 tensor to a plain Python data type, you can use the `.item()` method. The `.item()` method retrieves the value of the rank-0 tensor as a native Python scalar.\n",
    "\n",
    "Here's an example to demonstrate the conversion of a rank-0 tensor to a plain Python data type:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "tensor = torch.tensor(5)  # Create a rank-0 tensor with value 5\n",
    "\n",
    "# Convert rank-0 tensor to plain Python data type\n",
    "value = tensor.item()\n",
    "\n",
    "print(\"Tensor value:\", tensor)\n",
    "print(\"Plain Python data type:\", type(value))\n",
    "print(\"Value as a plain Python value:\", value)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Tensor value: tensor(5)\n",
    "Plain Python data type: <class 'int'>\n",
    "Value as a plain Python value: 5\n",
    "```\n",
    "\n",
    "In the example above, we create a rank-0 tensor `tensor` with a value of 5. To convert it to a plain Python data type, we call the `.item()` method on the tensor and store the result in the `value` variable. The `value` is then printed, which represents the rank-0 tensor as a plain Python integer value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393c0a8",
   "metadata": {},
   "source": [
    "13. How does elementwise arithmetic help us speed up matmul?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9edce",
   "metadata": {},
   "source": [
    "Elementwise arithmetic operations do not directly speed up matrix multiplication (`matmul`), but they can be used in conjunction with other techniques to optimize the overall performance of matrix multiplication operations. Here are a few ways elementwise arithmetic can be helpful in speeding up `matmul`:\n",
    "\n",
    "1. Broadcasting: Elementwise arithmetic operations often involve arrays of different shapes. Broadcasting is a technique in NumPy/PyTorch that allows for elementwise operations between arrays of different shapes by automatically expanding the smaller array to match the shape of the larger array. Broadcasting can be leveraged to efficiently perform elementwise operations during matrix multiplication, reducing the need for explicit loops.\n",
    "\n",
    "2. Parallelization: Many elementwise arithmetic operations, such as addition, subtraction, or multiplication, can be parallelized efficiently using SIMD (Single Instruction, Multiple Data) instructions or GPU acceleration. By leveraging parallel computing capabilities, elementwise operations can be performed simultaneously on multiple elements, leading to faster execution of the matrix multiplication operation as a whole.\n",
    "\n",
    "3. Fusion with other operations: Elementwise arithmetic operations can be fused with other operations within a computation graph or computational kernel. For example, modern deep learning frameworks like TensorFlow or PyTorch use automatic differentiation and computational graph optimization techniques. These frameworks can fuse elementwise operations with other operations like matrix multiplication, allowing for better memory access patterns and reducing overhead, which can result in faster overall execution.\n",
    "\n",
    "It's important to note that elementwise arithmetic itself does not directly optimize the speed of matrix multiplication but rather complements other techniques or optimizations that improve the performance of matrix multiplication operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e2af4",
   "metadata": {},
   "source": [
    "14. What are the broadcasting rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2acce5",
   "metadata": {},
   "source": [
    "Broadcasting is a technique used in NumPy and PyTorch to perform elementwise operations between arrays of different shapes. The broadcasting rules determine how arrays of different shapes can be broadcasted to have compatible shapes for elementwise operations. The broadcasting rules are as follows:\n",
    "\n",
    "1. Dimensions with size 1: If the two arrays have different numbers of dimensions, the array with fewer dimensions is padded with ones on the left until the numbers of dimensions match.\n",
    "\n",
    "2. Dimensions of size 1 are expanded: For each dimension where one array has size 1 and the other array has a greater size, the array with size 1 is stretched or replicated along that dimension to match the size of the other array.\n",
    "\n",
    "3. Dimensions of non-equal size must be compatible: If the arrays have the same number of dimensions and their sizes do not match for at least one dimension, the dimension sizes must be equal or one of them must be 1. Otherwise, broadcasting cannot be performed, and the operation will raise a ValueError.\n",
    "\n",
    "4. Output shape: The resulting shape of the broadcasted arrays is determined by taking the elementwise maximum of the sizes along each dimension of the input arrays.\n",
    "\n",
    "Here's an example to illustrate the broadcasting rules:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3]])\n",
    "B = np.array([[4], [5]])\n",
    "\n",
    "C = A + B  # Elementwise addition\n",
    "\n",
    "print(\"Array A:\\n\", A)\n",
    "print(\"Array B:\\n\", B)\n",
    "print(\"Array C:\\n\", C)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Array A:\n",
    " [[1 2 3]]\n",
    "Array B:\n",
    " [[4]\n",
    " [5]]\n",
    "Array C:\n",
    " [[5 6 7]\n",
    " [6 7 8]]\n",
    "```\n",
    "\n",
    "In this example, we have arrays `A` and `B` with different shapes. Array `A` is 1x3, and array `B` is 2x1. By applying elementwise addition (`+` operator), broadcasting is applied, and the arrays are expanded to match their shapes. The resulting array `C` has the shape 2x3, and the elementwise addition is performed between corresponding elements of `A` and `B`.\n",
    "\n",
    "By following the broadcasting rules, arrays of different shapes can be combined in elementwise operations, avoiding the need to explicitly reshape or duplicate arrays to match their shapes. Broadcasting allows for more concise and efficient code when performing elementwise arithmetic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5977f",
   "metadata": {},
   "source": [
    "15. What is expand_as? Show an example of how it can be used to match the results of\n",
    "broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d110018",
   "metadata": {},
   "source": [
    "In PyTorch, the `expand_as` method is used to expand the shape of a tensor to match the shape of another tensor. It returns a new tensor with the expanded shape.\n",
    "\n",
    "Here's an example to illustrate how `expand_as` can be used to match the results of broadcasting:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "A = torch.tensor([[1, 2, 3]])\n",
    "B = torch.tensor([[4], [5]])\n",
    "\n",
    "expanded_B = B.expand_as(A)  # Expand B to match the shape of A\n",
    "\n",
    "C = A + expanded_B  # Elementwise addition\n",
    "\n",
    "print(\"Tensor A:\\n\", A)\n",
    "print(\"Tensor B:\\n\", B)\n",
    "print(\"Expanded B:\\n\", expanded_B)\n",
    "print(\"Resulting Tensor C:\\n\", C)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Tensor A:\n",
    " tensor([[1, 2, 3]])\n",
    "Tensor B:\n",
    " tensor([[4],\n",
    "        [5]])\n",
    "Expanded B:\n",
    " tensor([[4, 4, 4],\n",
    "        [5, 5, 5]])\n",
    "Resulting Tensor C:\n",
    " tensor([[5, 6, 7],\n",
    "        [6, 7, 8]])\n",
    "```\n",
    "\n",
    "In this example, we have tensors `A` and `B` with different shapes. `A` is of shape 1x3, and `B` is of shape 2x1. To match the shape of `A`, we use the `expand_as` method on `B`, passing `A` as the argument. This expands the shape of `B` to match the shape of `A`, resulting in `expanded_B` with shape 1x3.\n",
    "\n",
    "We then perform elementwise addition between `A` and `expanded_B`, resulting in tensor `C`. By using `expand_as`, we ensure that both tensors have compatible shapes for the elementwise addition operation, allowing us to match the results of broadcasting.\n",
    "\n",
    "`expand_as` is a convenient method to align the shapes of tensors for elementwise operations, eliminating the need to manually reshape or duplicate tensors. It helps to ensure consistent and compatible shapes for efficient elementwise arithmetic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c3d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68edb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
